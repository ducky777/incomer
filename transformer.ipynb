{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as k\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_date_ordinal(cycle):\n",
    "    date_ordinal = np.array([dt.strptime(t.replace(\".\", \"/\"), \"%Y/%m/%d\").\\\n",
    "    toordinal() % cycle for t in np.array(data.Date)])\n",
    "\n",
    "    date_ordinal = (date_ordinal - np.min(date_ordinal)) \\\n",
    "        / (np.max(date_ordinal) - np.min(date_ordinal))\n",
    "    return date_ordinal\n",
    "\n",
    "# filename = 'data/US5001440.csv'\n",
    "filename = 'data/EURUSD60.csv'\n",
    "valid_idx = 3000\n",
    "\n",
    "data = pd.read_csv(filename, names=['Date', 'Time',\n",
    "                                    'Open', 'High',\n",
    "                                    'Low', 'Close',\n",
    "                                    'Volume'],\n",
    "                   header=0)\n",
    "\n",
    "lookbacks = 120\n",
    "total_bars = 15000\n",
    "num_forward_bars = 10\n",
    "\n",
    "hightail = np.array((data.High - data.Open) / data.Open)\n",
    "hightail = (hightail - np.min(hightail)) / (np.max(hightail) - np.min(hightail))\n",
    "\n",
    "lowtail = np.array((data.Low - data.Open) / data.Open)\n",
    "lowtail = (lowtail - np.min(lowtail)) / (np.max(lowtail) - np.min(lowtail))\n",
    "\n",
    "body = np.array((data.Close - data.Open) / data.Open)\n",
    "body = (body - np.min(body)) / (np.max(body) - np.min(body))\n",
    "\n",
    "op = np.array(data.Open)\n",
    "date_ordinal1 = get_date_ordinal(5)\n",
    "date_ordinal2 = get_date_ordinal(10)\n",
    "date_ordinal3 = get_date_ordinal(60)\n",
    "date_ordinal4 = get_date_ordinal(240)\n",
    "date_ordinal5 = get_date_ordinal(600)\n",
    "\n",
    "market_data = np.stack((op, hightail, lowtail, body,\n",
    "                        date_ordinal1, date_ordinal2, date_ordinal3,\n",
    "                        date_ordinal4, date_ordinal5), axis=1)\n",
    "\n",
    "df = pd.DataFrame(market_data)\n",
    "\n",
    "for i in range(1, lookbacks):\n",
    "    df['lb_ht'+str(i)] = df[1].shift(i)\n",
    "    df['lb_lt'+str(i)] = df[2].shift(i)\n",
    "    df['lb_body'+str(i)] = df[3].shift(i)\n",
    "    df['ord1'+str(i)] = df[4].shift(i)\n",
    "    df['ord2'+str(i)] = df[5].shift(i)\n",
    "    df['ord3'+str(i)] = df[6].shift(i)\n",
    "    df['ord4'+str(i)] = df[7].shift(i)\n",
    "    df['ord5'+str(i)] = df[8].shift(i)\n",
    "\n",
    "df = df.iloc[lookbacks:]\n",
    "dt = np.array(df)\n",
    "dt = dt[-total_bars:]\n",
    "x = dt[:, 9:]\n",
    "# x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "x = x.reshape(-1, lookbacks-1, 8)\n",
    "op = dt[:,0]\n",
    "\n",
    "y = []\n",
    "y_cat = []\n",
    "for i, _ in enumerate(op[:-num_forward_bars]):\n",
    "    pcnt_gain = []\n",
    "    rn = op[i:i+num_forward_bars+1]\n",
    "    for j, p in enumerate(rn[:-1]):\n",
    "        gain = (rn[j+1] - p) / p\n",
    "        pcnt_gain.append(gain)\n",
    "    # yt = (rn - rn.min()) / (rn.max() - rn.min())\n",
    "    y.append(pcnt_gain)\n",
    "    cat = 0\n",
    "    if np.argmin(rn) == 0:\n",
    "        cat = 1\n",
    "    elif np.argmax(rn) == 0:\n",
    "        cat = 2\n",
    "    y_cat.append(cat)\n",
    "\n",
    "y_cat = np.expand_dims(y_cat, -1)\n",
    "y = np.array(y)\n",
    "op = op[:-num_forward_bars]\n",
    "\n",
    "ymin, ymax = y.min(), y.max()\n",
    "y = (y - ymin) / (ymax - ymin)\n",
    "print(y.shape)\n",
    "print(y.max(), y.min())\n",
    "\n",
    "xtrain = x[:-num_forward_bars]\n",
    "xtrain = xtrain[:-valid_idx]\n",
    "\n",
    "ytrain = y_cat[:-valid_idx]\n",
    "oversample = SMOTE(sampling_strategy='not majority')\n",
    "x_over, y_over = oversample.fit_resample(xtrain.reshape(-1, (x.shape[1] * x.shape[2])), ytrain)\n",
    "x_over = x_over.reshape(-1, x.shape[1], x.shape[2])\n",
    "\n",
    "xtrain = np.array([*x_over, *xtrain])\n",
    "ytrain = np.array([*y_over, *ytrain])\n",
    "\n",
    "ytrain = ytrain.reshape(-1, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dd(eq):\n",
    "    end = np.argmax(np.maximum.accumulate(eq) - eq)\n",
    "    start = np.argmax(eq[:end])\n",
    "    return eq[end] - eq[start]\n",
    "\n",
    "\n",
    "def get_eq(predictions, verbose=1, reversed=False, rev_signal=False):\n",
    "    add_balance = 50000\n",
    "    min_elasped = 20\n",
    "\n",
    "    # gains = []\n",
    "    trades = []\n",
    "    eq = []\n",
    "    store_trades = []\n",
    "    entry_price = 0\n",
    "    entry_elasped = min_elasped\n",
    "    balance = []\n",
    "    closed = []\n",
    "\n",
    "    ops = op[-valid_idx:-num_forward_bars]\n",
    "    for j, (pr, o) in enumerate(zip(predictions, ops)):\n",
    "        csum = np.cumsum(pr)\n",
    "        lots = round(add_balance / o) * 10000\n",
    "        if reversed:\n",
    "            lots = -lots\n",
    "        # lots = 1\n",
    "        if rev_signal:\n",
    "            pr = -pr\n",
    "        if pr == 1 and entry_elasped >= min_elasped:\n",
    "            if verbose:\n",
    "                print(f\"Entered: {o} / {lots} @ {j}\")\n",
    "            trades.append([o, lots])\n",
    "            entry_elasped = 0\n",
    "        elif pr == -1 and len(trades) > 0:\n",
    "            # closed.append(pnl)\n",
    "            trades = []\n",
    "            if verbose:\n",
    "                print(f\"Closed: {o} / {lots} @ {j}\")\n",
    "            # entry_elasped = min_elasped\n",
    "        pnl = 0\n",
    "        for _, l in trades:\n",
    "            pnl += (o - ops[j - 1]) * l\n",
    "        eq.append(pnl)\n",
    "        store_trades.append(trades)\n",
    "        entry_elasped += 1\n",
    "\n",
    "    eq = np.array(eq)\n",
    "    return eq\n",
    "\n",
    "\n",
    "def get_signals(model):\n",
    "    extractor = keras.models.Model(model.input, model.layers[-3].output)\n",
    "    predictions = extractor.predict(x[-valid_idx:-num_forward_bars], verbose=0)\n",
    "\n",
    "    base = extractor.predict(x[:-valid_idx], verbose=0)\n",
    "\n",
    "    cosine = cosine_similarity(predictions, base)\n",
    "\n",
    "    max_signals = np.argmax(cosine, axis=1)\n",
    "    denorm = y * (ymax - ymin) + ymin\n",
    "\n",
    "    signals = denorm[max_signals]\n",
    "\n",
    "    csum = np.cumsum(signals, axis=1)\n",
    "    argmax = np.argmax(csum, axis=1)\n",
    "    argmin = np.argmin(csum, axis=1)\n",
    "\n",
    "    sigs = []\n",
    "\n",
    "    for ma, mi in zip(argmax, argmin):\n",
    "        if mi == 0:\n",
    "            sigs.append(1)\n",
    "        elif ma == 0:\n",
    "            sigs.append(-1)\n",
    "        else:\n",
    "            sigs.append(0)\n",
    "\n",
    "    return np.array(sigs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"data/eurusd/EURUSD_best_lb30_f20_reverse.h5\")\n",
    "\n",
    "best_eq = 2\n",
    "best_rev = 2\n",
    "\n",
    "for ii in range(999999):\n",
    "    model.fit(xtrain, ytrain, epochs=1,validation_split=0.9,\n",
    "            batch_size=32, shuffle=True, verbose=0)\n",
    "    predictions = get_signals(model)\n",
    "    eq = get_eq(predictions, verbose=False)\n",
    "    try:\n",
    "        dd = calculate_dd(eq)\n",
    "    except Exception:\n",
    "        continue\n",
    "    if dd == 0:\n",
    "        dd = 1\n",
    "    score = np.sum(eq) / abs(dd)\n",
    "    if score > best_eq:\n",
    "        model.save(\"data/EURUSD_best_lb30_f20.h5\")\n",
    "        best_eq = score\n",
    "        print(f\"BEST: {best_eq}\")\n",
    "    elif -score > best_rev:\n",
    "        model.save(\"data/EURUSD_best_lb30_f20_reverse.h5\")\n",
    "        best_rev = -score\n",
    "        print(f\"BEST REVERSE: {best_rev}\")\n",
    "    else:\n",
    "        print(f\"{ii} -> {score}\")\n",
    "\n",
    "\n",
    "\n",
    "    eq = get_eq(predictions, verbose=False, rev_signal=True)\n",
    "    try:\n",
    "        dd = calculate_dd(eq)\n",
    "    except Exception:\n",
    "        continue\n",
    "    if dd == 0:\n",
    "        dd = 1\n",
    "    score = np.sum(eq) / abs(dd)\n",
    "    if score > best_eq:\n",
    "        model.save(\"data/EURUSD_best_lb30_f20_revsig.h5\")\n",
    "        best_eq = score\n",
    "        print(f\"BEST: {best_eq}\")\n",
    "    elif -score > best_rev:\n",
    "        model.save(\"data/EURUSD_best_lb30_f20_revsig_reverse.h5\")\n",
    "        best_rev = -score\n",
    "        print(f\"BEST REVERSE: {best_rev}\")\n",
    "    else:\n",
    "        print(f\"{ii} -> {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = keras.models.load_model(\"data/EURUSD_best_lb30_f20.h5\")\n",
    "\n",
    "sigs = get_signals(model)\n",
    "eq = get_eq(sigs, reversed=False)\n",
    "\n",
    "model = keras.models.load_model(\"data/EURUSD_best_lb30_f20_reverse.h5\")\n",
    "\n",
    "sigs = get_signals(model)\n",
    "eq2 = get_eq(sigs, reversed=True)\n",
    "\n",
    "model = keras.models.load_model(\"data/EURUSD_best_lb30_f20_revsig.h5\")\n",
    "\n",
    "sigs = get_signals(model)\n",
    "eq3 = get_eq(sigs, reversed=False, rev_signal=True)\n",
    "\n",
    "model = keras.models.load_model(\"data/EURUSD_best_lb30_f20_revsig_reverse.h5\")\n",
    "\n",
    "sigs = get_signals(model)\n",
    "eq4 = get_eq(sigs, reversed=True, rev_signal=True)\n",
    "\n",
    "eq = eq + eq2 + eq3 + eq4\n",
    "\n",
    "plt.plot(np.cumsum(eq))\n",
    "plt.show()\n",
    "\n",
    "dd = calculate_dd(eq)\n",
    "\n",
    "np.sum(eq) / -dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"${round(dd):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(eq) / len(eq)) * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"${round(np.sum(eq)):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/eurusd/x.npy\",x[-valid_idx:-num_forward_bars])\n",
    "np.save(\"data/eurusd/y.npy\",y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('hask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c11e1a3665d556f20d3632e616a091f1c7ce9a65fd514abec3cc31c26736e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
